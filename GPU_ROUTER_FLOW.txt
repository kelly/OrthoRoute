═══════════════════════════════════════════════════════════════════════════════
                    GPU PERSISTENT ROUTER - CODE FLOW
═══════════════════════════════════════════════════════════════════════════════

ENTRY POINT: main.py --test-manhattan
    ↓
    ↓  [Calls routing API]
    ↓
┌───────────────────────────────────────────────────────────────────────────┐
│ 1. route_multiple_nets() [line 2013]                                      │
│    - Main entry point for routing                                         │
│    - Parses requests into tasks                                           │
└───────────────────────────────────────────────────────────────────────────┘
    ↓
    ↓  [Starts pathfinder negotiation loop]
    ↓
┌───────────────────────────────────────────────────────────────────────────┐
│ 2. _pathfinder_negotiation() [line 2120]                                  │
│    - Iterates up to max_iterations (default: 10)                          │
│    - Updates costs, builds hotsets, detects stagnation                    │
│    - for iteration 1 to 10:                                               │
│        routed, failed = self._route_all(sub_tasks, ...)                   │
└───────────────────────────────────────────────────────────────────────────┘
    ↓
    ↓  [Routes nets with adaptive ROI]
    ↓
┌───────────────────────────────────────────────────────────────────────────┐
│ 3. _route_all() [line 2496]                                               │
│    - Routes nets with adaptive ROI and cost updates                       │
│    - Checks if GPU batching should be used:                               │
│      use_gpu_batching = (hasattr(self.solver, 'gpu_solver') and           │
│                          self.solver.gpu_solver is not None and           │
│                          total > 8)  # Need >8 nets for batching          │
│    - if use_gpu_batching:                                                 │
│        return self._route_all_batched_gpu(...)                            │
└───────────────────────────────────────────────────────────────────────────┘
    ↓
    ↓  [GPU batching path]
    ↓
┌───────────────────────────────────────────────────────────────────────────┐
│ 4. _route_all_batched_gpu() [line 2846]                                   │
│    - Routes nets in parallel GPU batches                                  │
│    ┌─────────────────────────────────────────────────────────────────┐   │
│    │ CRITICAL: Line 2971                                             │   │
│    │ use_persistent = GPUConfig.GPU_PERSISTENT_ROUTER                │   │
│    │ logger.info(f"[GPU-CONFIG] use_persistent={use_persistent}...")  │   │
│    └─────────────────────────────────────────────────────────────────┘   │
│                                                                            │
│    - Splits nets into SHORT (<50mm) and LONG (≥50mm) groups                │
│    - Processes in batches (default: 256 nets per batch)                   │
│                                                                            │
│    for batch_start in range(0, total, batch_size):                        │
│        batch_nets = ordered_nets[batch_start:batch_end]                   │
│                                                                            │
│        ┌────────────────────────────────────────────────────────────┐    │
│        │ AGENT-B1 FAST PATH: Line 2974                              │    │
│        │ if use_persistent:                                          │    │
│        │     logger.info("[GPU-CONFIG] Entering AGENT-B1 fast path") │    │
│        │     # Skip ROI extraction, use simplified prep              │    │
│        │     for net_id in batch_nets:                               │    │
│        │         roi_batch.append((src, dst, shared_csr, ...))       │    │
│        └────────────────────────────────────────────────────────────┘    │
│                                                                            │
│        # Route entire batch on GPU                                        │
│        ┌────────────────────────────────────────────────────────────┐    │
│        │ ALGORITHM SELECTION: Line 3146                              │    │
│        │ if use_persistent:                                          │    │
│        │     logger.info("[ALGORITHM] Using AGENT-B1 Persistent...") │    │
│        │     paths = self.solver.gpu_solver.route_batch_persistent(  │    │
│        │         roi_batch                                           │    │
│        │     )                                                       │    │
│        └────────────────────────────────────────────────────────────┘    │
│                                                                            │
│        # Process results and commit paths                                 │
│        for i, (net_id, ...) in enumerate(batch_metadata):                 │
│            global_path = [roi_nodes_cpu[idx] for idx in paths[i]]         │
│            self.accounting.commit_path(edge_indices)                      │
└───────────────────────────────────────────────────────────────────────────┘
    ↓
    ↓  [GPU kernel launch]
    ↓
┌───────────────────────────────────────────────────────────────────────────┐
│ 5. route_batch_persistent() [cuda_dijkstra.py:2416]                       │
│    - AGENT B1: Single-launch persistent routing kernel                    │
│    - Routes ALL nets in a SINGLE kernel launch                            │
│                                                                            │
│    Features:                                                               │
│    ✓ Agent A1 integration: Stamp-based state management                   │
│    ✓ Agent B1 enhancement: Device-side backtrace                          │
│    ✓ Single kernel launch: No per-iteration overhead                      │
│    ✓ Early termination: Nets stop when goal reached                       │
│                                                                            │
│    ┌──────────────────────────────────────────────────────────────┐      │
│    │ CUDA KERNEL: _persistent_routing_kernel                       │      │
│    │ - Each thread processes one net                               │      │
│    │ - Device-side wavefront expansion (no host sync)              │      │
│    │ - Device-side backtrace (no parent[] transfer)                │      │
│    │ - Stamp-based state clearing (no memset between nets)         │      │
│    │                                                                │      │
│    │ Performance:                                                   │      │
│    │   Launch overhead: ~7μs ONCE (vs 7μs × 100-200 iters)         │      │
│    │   Speedup: 100-200× reduction in overhead                     │      │
│    └──────────────────────────────────────────────────────────────┘      │
│                                                                            │
│    Returns: List[Optional[List[int]]] - paths for each net                │
└───────────────────────────────────────────────────────────────────────────┘
    ↓
    ↓  [Returns to caller]
    ↓
    SUCCESS: Nets routed in parallel with minimal overhead

═══════════════════════════════════════════════════════════════════════════════
                           CONFIGURATION SYSTEM
═══════════════════════════════════════════════════════════════════════════════

Two-Level Configuration (Correct Design):

┌──────────────────────────────────────────────────────────────────────────┐
│ LEVEL 1: PathFinderConfig [line 578-627]                                 │
│                                                                           │
│ class PathFinderConfig:                                                  │
│     use_gpu: bool = True  # Line 601 - Enable GPU solver                 │
│     batch_size: int = 256                                                │
│     max_iterations: int = 10                                             │
│     ...                                                                  │
│                                                                           │
│ Purpose: High-level algorithm parameters                                 │
│ Controls: WHETHER to initialize GPU solver                               │
└──────────────────────────────────────────────────────────────────────────┘

┌──────────────────────────────────────────────────────────────────────────┐
│ LEVEL 2: GPUConfig [line 527-572]                                        │
│                                                                           │
│ class GPUConfig:                                                         │
│     GPU_MODE = True  # Line 535 - Core GPU mode                          │
│     GPU_PERSISTENT_ROUTER = True  # Line 538 - Persistent kernel         │
│     GPU_DEVICE_COMPACTION = True  # Line 542 - Agent A2 compaction       │
│     GPU_DEVICE_ROI = True  # Line 546 - Device-side ROI gating           │
│     GPU_DEVICE_ACCOUNTING = True  # Line 549 - GPU cost updates          │
│     GPU_DEVICE_BACKTRACE = True  # Line 553 - Device-side backtrace      │
│     ...                                                                  │
│                                                                           │
│ Purpose: Low-level GPU optimization flags                                │
│ Controls: WHICH GPU features and algorithms to use                       │
└──────────────────────────────────────────────────────────────────────────┘

Initialization Flow:

1. __init__() [line 1619]
   config = PathFinderConfig()  # use_gpu defaults to True

2. _initialize_geometry() [line 1730]
   use_gpu_solver = config.use_gpu and GPU_AVAILABLE and CUDA_DIJKSTRA_AVAILABLE
   if use_gpu_solver:
       self.solver.gpu_solver = CUDADijkstra(...)  # Initialize GPU solver

3. _route_all_batched_gpu() [line 2971]
   use_persistent = GPUConfig.GPU_PERSISTENT_ROUTER  # Choose algorithm

Result: GPU enabled by default, persistent router selected by default

═══════════════════════════════════════════════════════════════════════════════
                          DEBUG LOGGING OUTPUT
═══════════════════════════════════════════════════════════════════════════════

When running with GPU persistent router, you'll see these logs:

[BATCH-1] Processing nets 1-256/320 (256 nets in parallel)
[GPU-CONFIG] use_persistent=True, GPUConfig.GPU_PERSISTENT_ROUTER=True
[GPU-CONFIG] Entering AGENT-B1 fast path
[AGENT-B1] Using GPU Persistent Router - skipping CPU ROI extraction
[AGENT-B1] Fast path batch prep complete: 256 nets with bounding boxes
[BATCH-1] Prep complete: ROI=0.00s, CSR=0.00s, Total=0.05s
[ALGORITHM] Using AGENT-B1 Persistent Router (batch_size=256)
[AGENT-B1-PERSISTENT] Routing 256 nets with single-launch persistent kernel
[BATCH-1] GPU routing complete: 0.23s (256 nets)
[BATCH-1] Results: 256 routed, 0 failed (1.00 ms/net avg)

[BATCH-2] Processing nets 257-320/320 (64 nets in parallel)
[GPU-CONFIG] use_persistent=True, GPUConfig.GPU_PERSISTENT_ROUTER=True
[GPU-CONFIG] Entering AGENT-B1 fast path
[AGENT-B1] Using GPU Persistent Router - skipping CPU ROI extraction
...

═══════════════════════════════════════════════════════════════════════════════
                          VERIFICATION STEPS
═══════════════════════════════════════════════════════════════════════════════

1. Quick Test (30 seconds):
   $ python test_gpu_integration.py

   Expected:
   ✓✓✓ INTEGRATION COMPLETE ✓✓✓
   Tests passed: 5/5

2. Runtime Verification (2 minutes):
   $ python main.py --test-manhattan 2>&1 | grep "\[GPU-CONFIG\]"

   Expected:
   [GPU-CONFIG] use_persistent=True, GPUConfig.GPU_PERSISTENT_ROUTER=True
   [GPU-CONFIG] Entering AGENT-B1 fast path

3. Full Test (5 minutes):
   $ python main.py --test-manhattan > test_output.txt 2>&1
   $ grep -E "\[GPU-CONFIG\]|\[AGENT-B1\]|\[ALGORITHM\]" test_output.txt

═══════════════════════════════════════════════════════════════════════════════
                              STATUS: ✓ COMPLETE
═══════════════════════════════════════════════════════════════════════════════

The GPU Persistent Router is:
✓ Correctly wired from entry to kernel
✓ Active by default (no configuration needed)
✓ Using GPUConfig (no environment variables)
✓ Verified by integration test
✓ Enhanced with debug logging

Ready for production deployment.
